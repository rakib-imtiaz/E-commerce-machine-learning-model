# -*- coding: utf-8 -*-
"""Gradient_Boost_E_commerce.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hm8GdvBQ7vNJi9U7uTsHBKA2SA8rxvrr
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import GradientBoostingClassifier
import joblib
import os

def load_and_prepare_data():
    # Load data directly from file
    try:
        df = pd.read_csv('E-Commerce Data.csv', encoding='latin-1')
    except FileNotFoundError:
        df = pd.read_csv('datasets/E-Commerce Data.csv', encoding='latin-1')
    
    df = df.dropna()

    # Convert 'InvoiceDate' to datetime
    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
    df['InvoiceMonth'] = df['InvoiceDate'].dt.month

    # Initialize label encoders for each categorical column
    label_encoders = {}
    categorical_cols = ['StockCode', 'Country']
    
    for col in categorical_cols:
        le = LabelEncoder()
        # Add a special 'unknown' category
        unique_values = np.append(df[col].astype(str).unique(), 'unknown')
        le.fit(unique_values)
        df[col] = le.transform(df[col].astype(str))
        label_encoders[col] = le

    # Define target variable (large transaction)
    df['LargeTransaction'] = (df['Quantity'] > 50).astype(int)

    # Select features for training
    feature_cols = ['StockCode', 'Country', 'UnitPrice', 'InvoiceMonth']
    X = df[feature_cols]
    y = df['LargeTransaction']

    # Convert to float32 for better memory usage
    X = X.astype(np.float32)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    return X_train, X_test, y_train, y_test, label_encoders

def train_model():
    X_train, X_test, y_train, y_test, label_encoders = load_and_prepare_data()
    
    # Initialize and train Gradient Boosting
    gb = GradientBoostingClassifier(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=3,
        random_state=42
    )
    gb.fit(X_train, y_train)
    
    # Create models directory if it doesn't exist
    if not os.path.exists('models'):
        os.makedirs('models')
    
    # Save the model and label encoders
    joblib.dump(gb, 'models/gradient_boost_model.pkl')
    joblib.dump(label_encoders, 'models/gb_label_encoders.pkl')
    
    return gb, label_encoders, (X_train, X_test, y_train, y_test)

if __name__ == "__main__":
    model, label_encoders, (X_train, X_test, y_train, y_test) = train_model()
else:
    # Load pre-trained model if exists, otherwise train
    try:
        model = joblib.load('models/gradient_boost_model.pkl')
        label_encoders = joblib.load('models/gb_label_encoders.pkl')
    except:
        model, label_encoders, _ = train_model()